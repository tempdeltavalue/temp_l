{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d28930a-8b8b-44e6-8097-c99375bf37c9",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6340211a-db64-458f-b3fb-4b87f09ab743",
   "metadata": {},
   "source": [
    "### Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd50d6e-8d3a-4b29-8536-4e04f19dc13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd53aa4c-b83b-41a3-9b73-498aca71e2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tempdelta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70df8f69-9d40-4467-9755-5582b4ca5178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"BAAI/bge-small-en\"\n",
    "model = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3502aaba-3e8a-42a6-9665-9d59304e798b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd0ab4-6687-4b54-aff7-b30aa96f3698",
   "metadata": {},
   "source": [
    "### Define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad17db1-e4b6-4c54-9242-905fb9cd9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import InputExample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfaf8851-5d25-45c0-876a-5dbccaff0a32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'InputExample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m examples\n\u001b[0;32m     14\u001b[0m math_sentences \u001b[38;5;241m=\u001b[39m math_example_text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m math_data \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_math_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmath_sentences\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m100\u001b[39m]\n",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m, in \u001b[0;36mgenerate_math_dataset\u001b[1;34m(math_sentences)\u001b[0m\n\u001b[0;32m      7\u001b[0m examples \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m math_sentences:\n\u001b[1;32m----> 9\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mInputExample\u001b[49m(texts\u001b[38;5;241m=\u001b[39m[sentence, sentence]) \u001b[38;5;66;03m# temp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     examples\u001b[38;5;241m.\u001b[39mappend(example)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m examples\n",
      "\u001b[1;31mNameError\u001b[0m: name 'InputExample' is not defined"
     ]
    }
   ],
   "source": [
    "math_example_path = os.getcwd() + '/data/What_Is_Mathematics_An_Elementary_Approach_to_Ideas_and_Methods.txt'\n",
    "\n",
    "with open(math_example_path, \"r\",  encoding=\"utf8\") as f:\n",
    "     math_example_text = f.read()\n",
    "\n",
    "def generate_math_dataset(math_sentences):\n",
    "    examples = []\n",
    "    for sentence in math_sentences:\n",
    "        example = InputExample(texts=[sentence, sentence]) # temp\n",
    "        examples.append(example)\n",
    "\n",
    "    return examples\n",
    "\n",
    "math_sentences = math_example_text.split(\"\\n\")\n",
    "math_data = generate_math_dataset(math_sentences)[0:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e26aa72e-c158-4d6c-862f-bb555e5e456d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_math_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m      math_example_text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      5\u001b[0m math_sentences \u001b[38;5;241m=\u001b[39m math_example_text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m math_data \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_math_dataset\u001b[49m(math_sentences)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m100\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(TRAIN_DATASET_FPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      9\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generate_math_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(TRAIN_DATASET_FPATH, 'r+') as f:\n",
    "    train_dataset = json.load(f)\n",
    "    \n",
    "TRAIN_DATASET_FPATH = os.getcwd() + '/finetune_data/train_dataset.json'\n",
    "VAL_DATASET_FPATH = os.getcwd() + '/finetune_data/val_dataset.json'\n",
    "\n",
    "# We use a very small batchsize to run this toy example on a local machine. \n",
    "# This should typically be much larger. \n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2713df64-b708-48f9-8a0a-505ee24ec381",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_DATASET_FPATH, 'r+') as f:\n",
    "    train_dataset = json.load(f)\n",
    "\n",
    "with open(VAL_DATASET_FPATH, 'r+') as f:\n",
    "    val_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f07e006a-9a08-4961-b639-66a7a65bc603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_db_dataset(train_dataset):\n",
    "    dataset = train_dataset\n",
    "    \n",
    "    corpus = dataset['corpus']\n",
    "    queries = dataset['queries']\n",
    "    relevant_docs = dataset['relevant_docs']\n",
    "    \n",
    "    \n",
    "    \n",
    "    examples = []\n",
    "    for query_id, query in queries.items():\n",
    "        node_id = relevant_docs[query_id][0]\n",
    "        text = corpus[node_id]\n",
    "        example = InputExample(texts=[query, text])\n",
    "        examples.append(example)\n",
    "\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b7f2f2-0012-4ec7-8f44-1909d42c84b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_math_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m math_data \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_math_dataset\u001b[49m(math_sentences)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m100\u001b[39m]\n\u001b[0;32m      2\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#generate_db_dataset(train_dataset), \u001b[39;00m\n\u001b[0;32m      4\u001b[0m     math_data,\n\u001b[0;32m      5\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE\n\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generate_math_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "loader = DataLoader(\n",
    "    #generate_db_dataset(train_dataset), \n",
    "    math_data,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8acef2-8618-4afa-84e0-cd959d181208",
   "metadata": {},
   "source": [
    "### Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bd4e6b0f-8ffd-4f40-bbc8-bb307c32e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.sbert.net/docs/package_reference/losses.html#multiplenegativesrankingloss\n",
    "from sentence_transformers import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "928eec1f-0f47-4bac-9189-7b791e81024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = losses.MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95044745-c271-40b3-a6d9-dd646ab281de",
   "metadata": {},
   "source": [
    "### Define evaluator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a4cb4df8-d12b-4956-85d5-447a24331cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "64ab1591-ce7e-4990-a708-9b22a7ce0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = val_dataset\n",
    "\n",
    "corpus = dataset['corpus']\n",
    "queries = dataset['queries']\n",
    "relevant_docs = dataset['relevant_docs']\n",
    "\n",
    "# evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b6607-9d4b-472e-b9e3-8e618aa58a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de5deb95-6d9a-4da8-ba46-f0317b12d6df",
   "metadata": {},
   "source": [
    "### Run training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "99ff9b09-c191-4ac0-a89e-629031e648d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f3b6afdf-87d6-40be-b6fd-36f89dbb3612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:07,  1.22it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:06,  1.33it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:05,  1.29it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.38it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.41it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.35it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.30it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:06<00:01,  1.33it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.35it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.36it/s]\u001b[A\n",
      "Epoch:  10%|███████▌                                                                    | 1/10 [00:07<01:06,  7.36s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:06,  1.47it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.45it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:05,  1.37it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.43it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.43it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.36it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.30it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:06<00:01,  1.32it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.34it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\u001b[A\n",
      "Epoch:  20%|███████████████▏                                                            | 2/10 [00:14<00:59,  7.41s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:05,  1.54it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.53it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:04,  1.44it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:03,  1.52it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.51it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.43it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.37it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.38it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.39it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.40it/s]\u001b[A\n",
      "Epoch:  30%|██████████████████████▊                                                     | 3/10 [00:21<00:51,  7.30s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:06,  1.50it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:05,  1.40it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.48it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.40it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.33it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.36it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.38it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.38it/s]\u001b[A\n",
      "Epoch:  40%|██████████████████████████████▍                                             | 4/10 [00:29<00:43,  7.27s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:06,  1.40it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.43it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:05,  1.36it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.44it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.44it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.39it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.35it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.38it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.39it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.40it/s]\u001b[A\n",
      "Epoch:  50%|██████████████████████████████████████                                      | 5/10 [00:36<00:36,  7.24s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:05,  1.53it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.50it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:05,  1.38it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.45it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.48it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.41it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.36it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.40it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.40it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.41it/s]\u001b[A\n",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 6/10 [00:43<00:28,  7.19s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:06,  1.48it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.48it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:04,  1.42it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.41it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.37it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.39it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.38it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.39it/s]\u001b[A\n",
      "Epoch:  70%|█████████████████████████████████████████████████████▏                      | 7/10 [00:50<00:21,  7.19s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:05,  1.58it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:04,  1.41it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.45it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.47it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.38it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.32it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.35it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.36it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.38it/s]\u001b[A\n",
      "Epoch:  80%|████████████████████████████████████████████████████████████▊               | 8/10 [00:57<00:14,  7.22s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:05,  1.58it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.53it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:04,  1.41it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.45it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.43it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.35it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.30it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:06<00:01,  1.32it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.34it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\u001b[A\n",
      "Epoch:  90%|████████████████████████████████████████████████████████████████████▍       | 9/10 [01:05<00:07,  7.28s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:06,  1.49it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:04,  1.44it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.47it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.46it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.40it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.33it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.35it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.35it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\u001b[A\n",
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [01:12<00:00,  7.27s/it]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Definition of of callbak should be after model init\n",
    "class MLFlowCallback:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def __call__(self, score, epoch, steps) -> None:\n",
    "        print(self.model)\n",
    "        print(score, epoch, steps)\n",
    "        mlflow.log_metric('score', score)\n",
    "        # https://mlflow.org/docs/latest/tracking/artifacts-stores.html\n",
    "\n",
    "mlflow_callback = MLFlowCallback(model)\n",
    "           \n",
    "warmup_steps = int(len(loader) * EPOCHS * 0.1)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model.fit(\n",
    "        train_objectives=[(loader, loss)],\n",
    "        epochs=EPOCHS,\n",
    "        warmup_steps=warmup_steps,\n",
    "        output_path='exp_finetune',\n",
    "        show_progress_bar=True,\n",
    "        #evaluator=evaluator, \n",
    "        evaluation_steps=50,\n",
    "        callback=mlflow_callback \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f6304d1f-aecf-42ff-9852-03f49bde8f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### llamaindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0851e2dc-6346-4a27-be11-a9874ec66493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tempdelta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name='C:\\\\Users\\\\tempdelta\\\\Desktop\\\\temp_l\\\\exp_finetune' embed_batch_size=10 callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x0000015CB0C00410> tokenizer_name='C:\\\\Users\\\\tempdelta\\\\Desktop\\\\temp_l\\\\exp_finetune' max_length=512 pooling=<Pooling.CLS: 'cls'> normalize=True query_instruction=None text_instruction=None cache_folder=None\n"
     ]
    }
   ],
   "source": [
    "from llama_index import ServiceContext, VectorStoreIndex\n",
    "from llama_index.schema import TextNode\n",
    "from llama_index.embeddings import HuggingFaceEmbedding# OpenAIEmbedding\n",
    "import os\n",
    "\n",
    "MODEL_PATH = os.getcwd() + r'\\exp_finetune'\n",
    "embed_model = HuggingFaceEmbedding(MODEL_PATH)\n",
    "\n",
    "print(embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221944fc-538f-4e85-809b-3e7f3ff244a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'math_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m top_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m      3\u001b[0m service_context \u001b[38;5;241m=\u001b[39m ServiceContext\u001b[38;5;241m.\u001b[39mfrom_defaults(embed_model\u001b[38;5;241m=\u001b[39membed_model, llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m math_nodes \u001b[38;5;241m=\u001b[39m [TextNode(id_\u001b[38;5;241m=\u001b[39mexample\u001b[38;5;241m.\u001b[39mtexts[\u001b[38;5;241m0\u001b[39m], text\u001b[38;5;241m=\u001b[39mexample\u001b[38;5;241m.\u001b[39mtexts[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmath_data\u001b[49m] \n\u001b[0;32m      7\u001b[0m nodes \u001b[38;5;241m=\u001b[39m [TextNode(id_\u001b[38;5;241m=\u001b[39mid_, text\u001b[38;5;241m=\u001b[39mtext) \u001b[38;5;28;01mfor\u001b[39;00m id_, text \u001b[38;5;129;01min\u001b[39;00m corpus\u001b[38;5;241m.\u001b[39mitems()] \n\u001b[0;32m      8\u001b[0m index \u001b[38;5;241m=\u001b[39m VectorStoreIndex(\n\u001b[0;32m      9\u001b[0m     nodes, \n\u001b[0;32m     10\u001b[0m     service_context\u001b[38;5;241m=\u001b[39mservice_context, \n\u001b[0;32m     11\u001b[0m     show_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'math_data' is not defined"
     ]
    }
   ],
   "source": [
    "# https://github.com/run-llama/llama_index/issues/10051\n",
    "top_k = 5\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=None)\n",
    "\n",
    "math_nodes = [TextNode(id_=example.texts[0], text=example.texts[0]) for example in math_data] \n",
    "\n",
    "nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()] \n",
    "index = VectorStoreIndex(\n",
    "    nodes, \n",
    "    service_context=service_context, \n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "retriever = index.as_retriever(similarity_top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ee10f-d5e2-4c37-9943-041f7d70ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist(persist_dir=\"./storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a22996c-909f-491b-b6a0-5c2296d33453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5665834-450e-4f62-add5-574ab7010398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "llm_model = GPT2LMHeadModel.from_pretrained('gpt2') # 548 mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ec34de27-6b73-434f-9375-7877cdcd98b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you love me?\"\n",
      "\n",
      "\"I love you,\" she said. \"I love you.\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_ids = tokenizer.encode(\"Do you love me\", add_special_tokens=True, return_tensors='pt')\n",
    "output = llm_model.generate(input_ids)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43de76db-05bf-4d5d-9e40-0d13a119fb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50257, 768])\n",
      "False\n",
      "torch.Size([1024, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 2304])\n",
      "False\n",
      "torch.Size([2304])\n",
      "False\n",
      "torch.Size([768, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 3072])\n",
      "False\n",
      "torch.Size([3072])\n",
      "False\n",
      "torch.Size([3072, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 2304])\n",
      "False\n",
      "torch.Size([2304])\n",
      "False\n",
      "torch.Size([768, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 3072])\n",
      "False\n",
      "torch.Size([3072])\n",
      "False\n",
      "torch.Size([3072, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 2304])\n",
      "False\n",
      "torch.Size([2304])\n",
      "False\n",
      "torch.Size([768, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 3072])\n",
      "False\n",
      "torch.Size([3072])\n",
      "False\n",
      "torch.Size([3072, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 2304])\n",
      "False\n",
      "torch.Size([2304])\n",
      "False\n",
      "torch.Size([768, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 3072])\n",
      "False\n",
      "torch.Size([3072])\n",
      "False\n",
      "torch.Size([3072, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 2304])\n",
      "False\n",
      "torch.Size([2304])\n",
      "False\n",
      "torch.Size([768, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 3072])\n",
      "False\n",
      "torch.Size([3072])\n",
      "False\n",
      "torch.Size([3072, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 2304])\n",
      "False\n",
      "torch.Size([2304])\n",
      "False\n",
      "torch.Size([768, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 3072])\n",
      "False\n",
      "torch.Size([3072])\n",
      "False\n",
      "torch.Size([3072, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 2304])\n",
      "False\n",
      "torch.Size([2304])\n",
      "False\n",
      "torch.Size([768, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 3072])\n",
      "False\n",
      "torch.Size([3072])\n",
      "False\n",
      "torch.Size([3072, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 2304])\n",
      "False\n",
      "torch.Size([2304])\n",
      "False\n",
      "torch.Size([768, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 3072])\n",
      "False\n",
      "torch.Size([3072])\n",
      "False\n",
      "torch.Size([3072, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 2304])\n",
      "False\n",
      "torch.Size([2304])\n",
      "False\n",
      "torch.Size([768, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 3072])\n",
      "False\n",
      "torch.Size([3072])\n",
      "False\n",
      "torch.Size([3072, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 2304])\n",
      "False\n",
      "torch.Size([2304])\n",
      "False\n",
      "torch.Size([768, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 3072])\n",
      "False\n",
      "torch.Size([3072])\n",
      "False\n",
      "torch.Size([3072, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 2304])\n",
      "False\n",
      "torch.Size([2304])\n",
      "False\n",
      "torch.Size([768, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 3072])\n",
      "False\n",
      "torch.Size([3072])\n",
      "False\n",
      "torch.Size([3072, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 2304])\n",
      "False\n",
      "torch.Size([2304])\n",
      "False\n",
      "torch.Size([768, 768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768])\n",
      "False\n",
      "torch.Size([768, 3072])\n",
      "False\n",
      "torch.Size([3072])\n",
      "False\n",
      "torch.Size([3072, 768])\n",
      "True\n",
      "torch.Size([768])\n",
      "True\n",
      "torch.Size([768])\n",
      "True\n",
      "torch.Size([768])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "llm_model.train()\n",
    "\n",
    "for i, params in enumerate(llm_model.parameters()):\n",
    "    print(params.shape)\n",
    "    if i > len(list((llm_model.parameters()))) - 5:\n",
    "        params.requires_grad = True\n",
    "    else:\n",
    "        params.requires_grad = False\n",
    "\n",
    "    print(params.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "71e8adea-3c54-4241-b72f-48dcd03233d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "encoded_data = tokenizer.batch_encode_plus(math_sentences, add_special_tokens=True, return_tensors='pt', padding=True)\n",
    "BATH_SIZE = 10\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "        \n",
    "batch_data = chunks(encoded_data[\"input_ids\"], BATH_SIZE)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37f08031-e073-4fbd-ad30-370d20dc9de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss  tensor(9.2864, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(9.3437, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.9947, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(9.3165, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(9.1783, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.9976, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.9499, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(9.0616, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(9.1298, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(9.0342, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.9833, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(9.0470, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.8640, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.8077, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.8197, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.8974, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.5935, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.8767, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.4570, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.4546, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.3810, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.5811, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.3937, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.5006, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.3146, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.5126, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.3954, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.3857, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.3791, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.2321, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.4859, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.8276, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.0562, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.2758, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.2213, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.3016, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.4194, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.1843, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.3583, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.2464, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.2287, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.2330, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.1322, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.2989, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.0288, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.1728, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.0768, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.1819, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.0386, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.1177, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.1168, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.9149, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.1172, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.7479, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.1256, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.9937, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.9129, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(8.0749, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.9710, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.9129, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.9550, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.8330, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.8233, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.8892, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.9487, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.8514, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.7977, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.7095, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.7525, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.6068, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.7287, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.6770, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.6107, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.7373, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.3972, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.5408, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.4182, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.7816, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.4166, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.3696, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.6561, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.5592, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.4567, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.6675, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.3551, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.4500, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.5998, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.6653, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.6589, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.3545, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.5311, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.6836, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.5621, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.4495, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.3567, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.5074, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.3801, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.4257, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.5704, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.1926, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.2494, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.3495, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.1823, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.2857, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.0908, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.3169, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.0489, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.2169, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.2373, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.1814, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.9795, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.0501, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.0242, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.7215, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.9438, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(7.1908, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.8042, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.7480, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.8255, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.8352, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.8464, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.7773, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.8214, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.5341, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.8054, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.6326, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.9432, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.8977, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.8071, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.8131, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.6688, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.8511, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.7457, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.7629, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.5675, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.5181, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.5402, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.5690, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.6873, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.6568, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.6941, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.8299, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.4536, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.7140, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.5146, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.5671, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.2533, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.4071, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.2940, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.3248, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.2814, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.3059, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.4109, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.2331, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.2139, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.1643, grad_fn=<NllLossBackward0>)\n",
      "batch loss  tensor(6.1275, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m llm_model(batch, labels\u001b[38;5;241m=\u001b[39mbatch)\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m---> 18\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch loss \u001b[39m\u001b[38;5;124m\"\u001b[39m, loss)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\optimizer.py:435\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    431\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    432\u001b[0m         update_group(g, ng) \u001b[38;5;28;01mfor\u001b[39;00m g, ng \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(groups, saved_groups)]\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__setstate__({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m: state, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_groups\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups})\n\u001b[1;32m--> 435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzero_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m, set_to_none: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    436\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sets the gradients of all optimized :class:`torch.Tensor` s to zero.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m            the step altogether).\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     foreach \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "output_dir = \"./finetuned_llm\"\n",
    "EPOCHS=5\n",
    "\n",
    "#encoded_data = tokenizer.encode(math_sentences, add_special_tokens=True, return_tensors='pt')\n",
    "\n",
    "llm_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "llm_model.config.eos_token_id = tokenizer.eos_token_id\n",
    "llm_model.config.vocab_size = llm_model.config.vocab_size + len(tokenizer.get_added_vocab())\n",
    "llm_model.resize_token_embeddings(len(tokenizer))\n",
    "optimizer = torch.optim.AdamW(llm_model.parameters(), lr=1e-5)\n",
    "\n",
    "for _ in range(EPOCHS):\n",
    "    for batch in batch_data: \n",
    "        outputs = llm_model(batch, labels=batch)\n",
    "        loss = outputs.loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        print(\"batch loss \", loss)\n",
    "        optimizer.step()\n",
    "\n",
    "    # Save the fine-tuned model every epoch \n",
    "    print(\"MODEL saved loss \", loss)\n",
    "    llm_model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e6e1682c-e907-49db-8bc4-457bfd13b7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you love me?\n",
      "I love you.\n",
      "\n",
      "\n",
      "I love you.\n",
      "I love\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"Do you love me ?\", add_special_tokens=True, return_tensors='pt')\n",
    "output = llm_model.generate(input_ids)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b8ff003d-d523-420f-8763-9b580450f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Mapping, Any\n",
    "\n",
    "from llama_index.llms import (\n",
    "    CustomLLM,\n",
    "    CompletionResponse,\n",
    "    CompletionResponseGen,\n",
    "    LLMMetadata,\n",
    ")\n",
    "from llama_index.llms.base import llm_completion_callback\n",
    "\n",
    "class OurLLM(CustomLLM):\n",
    "    context_window: int = 3900\n",
    "    num_output: int = 256\n",
    "    model_name: str = \"custom\"\n",
    "    dummy_response: str = \"My response\"\n",
    "\n",
    "    @property\n",
    "    def metadata(self) -> LLMMetadata:\n",
    "        \"\"\"Get LLM metadata.\"\"\"\n",
    "        return LLMMetadata(\n",
    "            context_window=self.context_window,\n",
    "            num_output=self.num_output,\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def complete(self, prompt: str, **kwargs: Any) -> CompletionResponse:\n",
    "        input_ids = tokenizer.encode(prompt, add_special_tokens=True, return_tensors='pt')\n",
    "        output = model.generate(input_ids)\n",
    "\n",
    "        return tokenizer.decode(output[0])\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def stream_complete(\n",
    "        self, prompt: str, **kwargs: Any\n",
    "    ) -> CompletionResponseGen:\n",
    "        response = \"\"\n",
    "        for token in self.dummy_response:\n",
    "            response += token\n",
    "            yield CompletionResponse(text=response, delta=token)\n",
    "\n",
    "\n",
    "# define our LLM\n",
    "llm = OurLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a89dc3ef-da97-4f74-9177-340dd648c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import load_index_from_storage\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index import ServiceContext\n",
    "\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    ")\n",
    "\n",
    "loaded_index = load_index_from_storage(storage_context=StorageContext.from_defaults(persist_dir=\"./storage\"), service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a00db1e-cf93-4371-a12b-dd9bacc57c9a",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca4e57f-c085-4474-8588-52010923b8b2",
   "metadata": {},
   "source": [
    "loaded_index = load_index_from_disk(StorageContext.from_defaults(persist_dir=\"./storage\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8779b48f-dcb7-4a73-9fcb-ce4de57bc672",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = loaded_index.as_retriever(similarity_top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "29ee61c6-8e83-4689-b42f-30b06d2ae9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='79f581ef-80dd-4d04-9e8e-ec128f95e6b1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='190905e6b7e3d6391293c392785096ddd4a66fc5553b42668936fbd624a55c83', text='Beingclassified  as  a  transportation  provider  would  result  in  a  VAT  (20%)  on  Gross  Bookings  or  on  the  service  fee  that  we  charge  Drivers,  both  retroactively  andprospectively.HMRC is considering a number of factors including our contractual Driver, Rider and intercompany arrangements, and HMRC is also expected toconsider the U.K. Supreme Court’s February 19, 2021 ruling on Drivers’ worker classification, in determining whether we should be classified as a provider oftransportation services.HMRC may update its assessment, which we would then review and discuss with HMRC.If we do not reach a satisfactory resolution afterexhausting HMRC’s review and appeals process, we would still be able to argue our case anew in the U.K. Tax Court, which may require the up-front payment tothe Tax Court (“pay-to-play”) of any final HMRC assessment to be held in escrow.We continue to believe that we have meritorious defense in these proceedings.Our  estimated  liability  is  inherently  subjective  due  to  the  complexity  and  uncertainty  of  these  matters  and  the  judicial  processes  in  certain  jurisdictions,therefore, the final outcome could be different from the estimated liability recorded.129', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.559511308389014),\n",
       " NodeWithScore(node=TextNode(id_='27550cab-b06c-488d-8b96-6a831bf556d8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='1ee9df287136c5441cb9f9348c81a1b0342f4314330956841b8aafebc800decf', text='If platform users engage in, or are subject to, criminal, violent, inappropriate, or dangerous activity that results in major safety incidents, our ability to attractand retain Drivers, consumers, merchants, shippers, and carriers may be harmed, which could have an adverse impact on our reputation, business, financialcondition, and operating results.We are not able to control or predict the actions of platform users and third parties, either during their use of our platform or otherwise, and we may be unableto protect or provide a safe environment for Drivers and consumers as a result of certain actions by Drivers, consumers, merchants, carriers, and third parties.Suchactions  may  result  in  injuries,  property  damage,  or  loss  of  life  for  consumers  and  third  parties,  or  business  interruption,  brand  and  reputational  damage,  orsignificant liabilities for us.Although we administer certain qualification processes for users of our platform, including background checks on Drivers throughthird-party service providers, these qualification processes and background checks may not expose all potentially relevant information and are limited in certainjurisdictions  according  to  national  and  local  laws,  and  our  third-party  service  providers  may  fail  to  conduct  such  background  checks  adequately  or  discloseinformation  that  could  be  relevant  to  a  determination  of  eligibility.Further,  the  qualification  and  background  check  standards  for  Couriers  are  generally  lessextensive than those conducted for Mobility Drivers.In addition, we do not independently test Drivers’ driving skills.Consequently, we expect to continue toreceive complaints from riders and other consumers, as well as actual or threatened legal action against us related to Driver conduct.We have also faced civillitigation alleging, among other things, inadequate Driver qualification processes and background checks, and general misrepresentations regarding the safety ofour platform.If Drivers or carriers, or individuals impersonating Drivers or carriers, engage in criminal activity, misconduct, or inappropriate conduct or use our platform asa conduit for criminal activity, consumers and shippers may not consider our products and offerings safe, and we may receive negative press coverage as a result ofour business relationship with such Driver or carrier, which would adversely impact our brand, reputation, and business.There have been numerous incidents andallegations worldwide of Drivers, or individuals impersonating Drivers, sexually assaulting, abusing, kidnapping and/or fatally injuring consumers, or otherwiseengaging in criminal activity while using our platform or claiming to use our platform.Furthermore, if consumers engage in criminal activity or misconduct whileusing our platform,  Drivers  and merchants  may be unwilling  to continue using our platform.In addition,  certain  regions  where we operate  have high rates  ofviolent crime, which has impacted Drivers and consumers in those regions.For example, in Latin America, there have been numerous and increasing reports ofDrivers and consumers being victimized by violent crime, such as armed robbery, violent assault, and rape, while taking or providing a trip on our platform.Ifother criminal, inappropriate, or other negative incidents occur due to the conduct of platform users or third parties, our ability to attract platform users may beharmed, and our business and financial results could be adversely affected.Public reporting or disclosure of reported safety information, including information about safety incidents reportedly occurring on or related to our platform,whether generated by us or third parties such as media or regulators, may adversely impact our business and financial results.Further,  we  may  be  subject  to  claims  of  significant  liability  based  on  traffic  accidents,  deaths,  injuries,  or  other  incidents  that  are  caused  by  Drivers,consumers, or third parties while using our platform, or even when Drivers, consumers, or third parties are not actively using our platform.On a smaller scale, wemay face litigation related to claims by Drivers for the actions of consumers or third parties.Furthermore, operating a motor vehicle is inherently dangerous.Inaddition, the growth of our Delivery offering has led to an increase in Couriers on two wheel vehicles such as scooters and bicycles, who are more vulnerable roadusers and face a more severe level of injury in the event of a collision than that faced while driving in a vehicle.For example, urban hazards such as unpaved oruneven roadways increase the risk and severity of potential injuries.In addition, Couriers, in particular those on two wheel vehicles predominantly in metropolitanareas, need to share, navigate, and at times contend with narrow and heavily congested roads occupied by cars, buses and light rail, especially during “rush” hours,all of which heighten the potential risk of injuries or death.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5594438972863129),\n",
       " NodeWithScore(node=TextNode(id_='f256d121-73dc-458c-b932-ccdd1d8f58c2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e75926c0a3ec8cc34b30eb80591c2567939d440cb046a98d6b360fb38fdb4abf', text='In the event we experience an ownership change within the meaning of Section 382 of the Internal Revenue Code (“IRC”), our ability to utilize net operatinglosses, tax credits and other tax attributes may be limited. The most recent analysis of our historical ownership changes was completed through December 31,2021. Based on the analysis, we do not anticipate a current limitation on the tax attributes.The following table reflects changes in gross unrecognized tax benefits (in millions):Year Ended December 31,201920202021Unrecognized tax benefits at beginning of year$394 $1,797 $2,293 Gross increases - current year tax positions1,566 353 239 Gross increases - prior year tax positions16 191 134 Gross decreases - prior year tax positions(36)(48)(9)Gross decreases - settlements with tax authorities(143)— — Unrecognized tax benefits at end of year$1,797 $2,293 $2,657 As of December 31, 2021, approximately $204 million of unrecognized tax benefits, if recognized, would impact the effective tax rate. The remaining $2.5billion of the unrecognized tax benefits would not impact the effective tax rate due to the valuation allowance against certain deferred tax assets.We  recognize  accrued  interest  and  penalties  related  to  unrecognized  tax  benefits  within  the  provision  for  income  taxes  in  the  consolidated  statements  ofoperations. The amount of interest and penalties accrued as of December 31, 2020 and 2021 was $12 million and $18 million, respectively.Although the timing of the resolution and/or closure of audits is highly uncertain, it is reasonably possible that the balance of gross unrecognized tax benefitscould significantly change in the next 12 months. Given the number of years remaining subject to examination and the number of matters being examined, we areunable to estimate the full range of possible adjustments to the balance of gross unrecognized tax benefits. Any changes to unrecognized tax benefits recorded as ofDecember 31, 2021 that are reasonably possible to occur within the next 12 months are not expected to be material.We are subject to taxation in the U.S. and various state and foreign jurisdictions. We are also under various state and other foreign income tax examinations.We believe that adequate amounts have been reserved in these jurisdictions. To the extent we have tax attribute carryforwards, the tax years in which the attributewas generated may still be adjusted upon examination by the federal, state or foreign tax authorities to the extent utilized in a future period.As of December 31, 2021, the open tax years for our major tax jurisdictions are as follows:JurisdictionTax YearsU.S. Federal2011 - 2021U.S. States2004 - 2021Brazil2016 - 2021Netherlands2018 - 2021Australia2017 - 2021As of December 31, 2021, the amount of accumulated foreign earnings of certain foreign subsidiaries that we intend to indefinitely reinvest is not material.Note 13 – Net Income (Loss) Per ShareBasic net income (loss) per share is computed by dividing net income (loss) by the weighted-average number of common shares outstanding for the periodspresented.  Diluted  net  income  (loss)  per  share  is  computed  by  giving  effect  to  all  potential  weighted  average  dilutive  common  stock.  The  dilutive  effect  ofoutstanding awards and convertible securities is reflected in diluted net income (loss) per share by application of the treasury stock method or if-converted method,as applicable.We  take  into  account  the  effect  on  consolidated  net  income  (loss)  per  share  of  dilutive  securities  of  entities  in  which  we  hold  equity  interests  that  areaccounted for using the equity method.123', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5508016721057023),\n",
       " NodeWithScore(node=TextNode(id_='9b962fc5-1c25-4717-abbf-4df63f02a920', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='3107c261f1d16632ec895e4b85ce36871c8a3c765783ac8a09cb38001409ba14', text=\"Payment for our services is generally due within 30 to 60 days upon completion of our performance obligation.Principal vs.Agent ConsiderationsJudgment is required in determining whether we are the principal or agent in transactions with Shippers.For each contract entered into with a Shipper wherewe are responsible for identifying and directing independent freight carriers to transport the Shipper's goods, we control the service before it is transferred to theShipper.We are primarily responsible for fulfilling the contract with the Shipper, including having discretion in selecting a qualified independent freight carrierthat meets the Shipper's specifications.We also have pricing discretion and negotiate separately the price(s) charged to Shippers and amounts paid to carriers.Accordingly, we are the principal in these transactions.In certain arrangements, we do not control the service provided to customers and recognize the relatedrevenue on a net basis.Contracts where we do not control the service before it is transferred to the Shipper are not material for the years ended December 31, 2019,2020 and 2021.89\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5481524898869209),\n",
       " NodeWithScore(node=TextNode(id_='d193a4ce-e62b-415c-a2e4-91dbc65ba284', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='90d0f311c339ca09b9d3d1bd8a784009b528cb0954aeadfc55cb4f6508945590', text='UNITED STATESSECURITIES AND EXCHANGE COMMISSIONWashington, D.C. 20549____________________________________________ FORM 10-K____________________________________________ (Mark One)☒ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934For the fiscal year ended December 31, 2021OR☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934For the transition period from_____ to _____            Commission File Number: 001-38902____________________________________________ UBER TECHNOLOGIES, INC.(Exact name of registrant as specified in its charter)____________________________________________ Delaware45-2647441(State or other jurisdiction of incorporation or organization)(I.R.S. Employer Identification No.)1515 3rd StreetSan Francisco, California 94158(Address of principal executive offices, including zip code)(415) 612-8582(Registrant’s telephone number, including area code) ____________________________________________Securities registered pursuant to Section 12(b) of the Act:Title of each classTrading Symbol(s)Name of each exchange on which registeredCommon Stock, par value $0.00001 per shareUBERNew York Stock ExchangeSecurities registered pursuant to Section 12(g) of the Act: NoneIndicate by check mark whether the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act. Yes  ☒ No ☐Indicate by check mark whether the registrant is not required to file reports pursuant to Section 13 or Section 15(d) of the Act. Yes  ☐ No  ☒Indicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during thepreceding 12 months (or for such shorter period that the registrant was required to file such reports), and (2) has been subject to such filing requirements for thepast 90 days. Yes  ☒ No ☐Indicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted pursuant to Rule 405 of RegulationS-T (§232.405 of this chapter) during the preceding 12 months (or for such shorter period that the registrant was required to submit such files). Yes  ☒ No ☐Indicate by check mark whether the registrant is a large accelerated filer, an accelerated filer, a non-accelerated filer, a smaller reporting company, or an emerginggrowth company. See the definitions of “large accelerated filer,” “accelerated filer,” “smaller reporting company,” and “emerging growth company” in Rule 12b-2of the Exchange Act.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5435779299583331)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687ec53c-453c-4933-a160-4cfaa288460a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
