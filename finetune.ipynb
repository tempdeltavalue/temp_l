{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d28930a-8b8b-44e6-8097-c99375bf37c9",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6340211a-db64-458f-b3fb-4b87f09ab743",
   "metadata": {},
   "source": [
    "### Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd50d6e-8d3a-4b29-8536-4e04f19dc13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd53aa4c-b83b-41a3-9b73-498aca71e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70df8f69-9d40-4467-9755-5582b4ca5178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"BAAI/bge-small-en\"\n",
    "model = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3502aaba-3e8a-42a6-9665-9d59304e798b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd0ab4-6687-4b54-aff7-b30aa96f3698",
   "metadata": {},
   "source": [
    "### Define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ad17db1-e4b6-4c54-9242-905fb9cd9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import InputExample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e26aa72e-c158-4d6c-862f-bb555e5e456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_example_path = os.getcwd() + '/data/What_Is_Mathematics_An_Elementary_Approach_to_Ideas_and_Methods.txt'\n",
    "\n",
    "with open(math_example_path, \"r\",  encoding=\"utf8\") as f:\n",
    "     math_example_text = f.read()\n",
    "math_sentences = math_example_text.split(\"\\n\")\n",
    "\n",
    "with open(TRAIN_DATASET_FPATH, 'r+') as f:\n",
    "    train_dataset = json.load(f)\n",
    "    \n",
    "TRAIN_DATASET_FPATH = os.getcwd() + '/finetune_data/train_dataset.json'\n",
    "VAL_DATASET_FPATH = os.getcwd() + '/finetune_data/val_dataset.json'\n",
    "\n",
    "# We use a very small batchsize to run this toy example on a local machine. \n",
    "# This should typically be much larger. \n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2713df64-b708-48f9-8a0a-505ee24ec381",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_DATASET_FPATH, 'r+') as f:\n",
    "    train_dataset = json.load(f)\n",
    "\n",
    "with open(VAL_DATASET_FPATH, 'r+') as f:\n",
    "    val_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f07e006a-9a08-4961-b639-66a7a65bc603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_db_dataset(train_dataset):\n",
    "    dataset = train_dataset\n",
    "    \n",
    "    corpus = dataset['corpus']\n",
    "    queries = dataset['queries']\n",
    "    relevant_docs = dataset['relevant_docs']\n",
    "    \n",
    "    \n",
    "    \n",
    "    examples = []\n",
    "    for query_id, query in queries.items():\n",
    "        node_id = relevant_docs[query_id][0]\n",
    "        text = corpus[node_id]\n",
    "        example = InputExample(texts=[query, text])\n",
    "        examples.append(example)\n",
    "\n",
    "    return examples\n",
    "\n",
    "def generate_math_dataset(math_sentences):\n",
    "    examples = []\n",
    "    for sentence in math_sentences:\n",
    "        example = InputExample(texts=[sentence, sentence])\n",
    "        examples.append(example)\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b7b7f2f2-0012-4ec7-8f44-1909d42c84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "math_data = generate_math_dataset(math_sentences)[0:100]\n",
    "loader = DataLoader(\n",
    "    #generate_db_dataset(train_dataset), \n",
    "    math_data,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8acef2-8618-4afa-84e0-cd959d181208",
   "metadata": {},
   "source": [
    "### Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bd4e6b0f-8ffd-4f40-bbc8-bb307c32e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.sbert.net/docs/package_reference/losses.html#multiplenegativesrankingloss\n",
    "from sentence_transformers import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "928eec1f-0f47-4bac-9189-7b791e81024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = losses.MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95044745-c271-40b3-a6d9-dd646ab281de",
   "metadata": {},
   "source": [
    "### Define evaluator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a4cb4df8-d12b-4956-85d5-447a24331cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "64ab1591-ce7e-4990-a708-9b22a7ce0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = val_dataset\n",
    "\n",
    "corpus = dataset['corpus']\n",
    "queries = dataset['queries']\n",
    "relevant_docs = dataset['relevant_docs']\n",
    "\n",
    "# evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b6607-9d4b-472e-b9e3-8e618aa58a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de5deb95-6d9a-4da8-ba46-f0317b12d6df",
   "metadata": {},
   "source": [
    "### Run training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "99ff9b09-c191-4ac0-a89e-629031e648d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f3b6afdf-87d6-40be-b6fd-36f89dbb3612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:07,  1.22it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:06,  1.33it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:05,  1.29it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.38it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.41it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.35it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.30it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:06<00:01,  1.33it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.35it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.36it/s]\u001b[A\n",
      "Epoch:  10%|███████▌                                                                    | 1/10 [00:07<01:06,  7.36s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:06,  1.47it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.45it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:05,  1.37it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.43it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.43it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.36it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.30it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:06<00:01,  1.32it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.34it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\u001b[A\n",
      "Epoch:  20%|███████████████▏                                                            | 2/10 [00:14<00:59,  7.41s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:05,  1.54it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.53it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:04,  1.44it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:03,  1.52it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.51it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.43it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.37it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.38it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.39it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.40it/s]\u001b[A\n",
      "Epoch:  30%|██████████████████████▊                                                     | 3/10 [00:21<00:51,  7.30s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:06,  1.50it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:05,  1.40it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.48it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.40it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.33it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.36it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.38it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.38it/s]\u001b[A\n",
      "Epoch:  40%|██████████████████████████████▍                                             | 4/10 [00:29<00:43,  7.27s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:06,  1.40it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.43it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:05,  1.36it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.44it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.44it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.39it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.35it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.38it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.39it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.40it/s]\u001b[A\n",
      "Epoch:  50%|██████████████████████████████████████                                      | 5/10 [00:36<00:36,  7.24s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:05,  1.53it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.50it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:05,  1.38it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.45it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.48it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.41it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.36it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.40it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.40it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.41it/s]\u001b[A\n",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 6/10 [00:43<00:28,  7.19s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:06,  1.48it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.48it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:04,  1.42it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.41it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.37it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.39it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.38it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.39it/s]\u001b[A\n",
      "Epoch:  70%|█████████████████████████████████████████████████████▏                      | 7/10 [00:50<00:21,  7.19s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:05,  1.58it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:04,  1.41it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.45it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.47it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.38it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.32it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.35it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.36it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.38it/s]\u001b[A\n",
      "Epoch:  80%|████████████████████████████████████████████████████████████▊               | 8/10 [00:57<00:14,  7.22s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:05,  1.58it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.53it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:04,  1.41it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.45it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.43it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.35it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.30it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:06<00:01,  1.32it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.34it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\u001b[A\n",
      "Epoch:  90%|████████████████████████████████████████████████████████████████████▍       | 9/10 [01:05<00:07,  7.28s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:06,  1.49it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:04,  1.44it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.47it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.46it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.40it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.33it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.35it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.35it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\u001b[A\n",
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [01:12<00:00,  7.27s/it]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Definition of of callbak should be after model init\n",
    "class MLFlowCallback:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def __call__(self, score, epoch, steps) -> None:\n",
    "        print(self.model)\n",
    "        print(score, epoch, steps)\n",
    "        mlflow.log_metric('score', score)\n",
    "        # https://mlflow.org/docs/latest/tracking/artifacts-stores.html\n",
    "\n",
    "mlflow_callback = MLFlowCallback(model)\n",
    "           \n",
    "warmup_steps = int(len(loader) * EPOCHS * 0.1)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model.fit(\n",
    "        train_objectives=[(loader, loss)],\n",
    "        epochs=EPOCHS,\n",
    "        warmup_steps=warmup_steps,\n",
    "        output_path='exp_finetune',\n",
    "        show_progress_bar=True,\n",
    "        #evaluator=evaluator, \n",
    "        evaluation_steps=50,\n",
    "        callback=mlflow_callback \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f6304d1f-aecf-42ff-9852-03f49bde8f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### llamaindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0851e2dc-6346-4a27-be11-a9874ec66493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name='C:\\\\Users\\\\tempdelta\\\\Desktop\\\\temp_l\\\\exp_finetune' embed_batch_size=10 callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x0000012F44FDB810> tokenizer_name='C:\\\\Users\\\\tempdelta\\\\Desktop\\\\temp_l\\\\exp_finetune' max_length=512 pooling=<Pooling.CLS: 'cls'> normalize=True query_instruction=None text_instruction=None cache_folder=None\n"
     ]
    }
   ],
   "source": [
    "from llama_index import ServiceContext, VectorStoreIndex\n",
    "from llama_index.schema import TextNode\n",
    "from llama_index.embeddings import HuggingFaceEmbedding# OpenAIEmbedding\n",
    "\n",
    "MODEL_PATH = os.getcwd() + r'\\exp_finetune'\n",
    "embed_model = HuggingFaceEmbedding(MODEL_PATH)\n",
    "\n",
    "print(embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "221944fc-538f-4e85-809b-3e7f3ff244a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|█████████████████████████████████████████████████████████| 395/395 [04:37<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/run-llama/llama_index/issues/10051\n",
    "top_k = 5\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=None)\n",
    "\n",
    "math_nodes = [TextNode(id_=example.texts[0], text=example.texts[0]) for example in math_data] \n",
    "\n",
    "nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()] \n",
    "index = VectorStoreIndex(\n",
    "    nodes, \n",
    "    service_context=service_context, \n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "retriever = index.as_retriever(similarity_top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "273ee10f-d5e2-4c37-9943-041f7d70ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist(persist_dir=\"./storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a89dc3ef-da97-4f74-9177-340dd648c028",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\n******\nCould not load OpenAI model. If you intended to use OpenAI, please check your OPENAI_API_KEY.\nOriginal error:\nNo API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n\nTo disable the LLM entirely, set llm=None.\n******",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\llama_index\\llms\\utils.py:29\u001b[0m, in \u001b[0;36mresolve_llm\u001b[1;34m(llm)\u001b[0m\n\u001b[0;32m     28\u001b[0m     llm \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[1;32m---> 29\u001b[0m     \u001b[43mvalidate_openai_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\llama_index\\llms\\openai_utils.py:379\u001b[0m, in \u001b[0;36mvalidate_openai_api_key\u001b[1;34m(api_key)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m openai_api_key:\n\u001b[1;32m--> 379\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(MISSING_API_KEY_ERROR_MESSAGE)\n",
      "\u001b[1;31mValueError\u001b[0m: No API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_index_from_storage\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StorageContext\n\u001b[1;32m----> 3\u001b[0m loaded_index \u001b[38;5;241m=\u001b[39m \u001b[43mload_index_from_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStorageContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_defaults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersist_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./storage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\llama_index\\indices\\loading.py:33\u001b[0m, in \u001b[0;36mload_index_from_storage\u001b[1;34m(storage_context, index_id, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     index_ids \u001b[38;5;241m=\u001b[39m [index_id]\n\u001b[1;32m---> 33\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[43mload_indices_from_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo index in storage context, check if you specified the right persist_dir.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\llama_index\\indices\\loading.py:78\u001b[0m, in \u001b[0;36mload_indices_from_storage\u001b[1;34m(storage_context, index_ids, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m index_struct\u001b[38;5;241m.\u001b[39mget_type()\n\u001b[0;32m     77\u001b[0m     index_cls \u001b[38;5;241m=\u001b[39m INDEX_STRUCT_TYPE_TO_INDEX_CLASS[type_]\n\u001b[1;32m---> 78\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mindex_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     indices\u001b[38;5;241m.\u001b[39mappend(index)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\llama_index\\indices\\vector_store\\base.py:52\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[1;34m(self, nodes, index_struct, service_context, storage_context, use_async, store_nodes_override, insert_batch_size, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_nodes_override \u001b[38;5;241m=\u001b[39m store_nodes_override\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size \u001b[38;5;241m=\u001b[39m insert_batch_size\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\llama_index\\indices\\base.py:62\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[1;34m(self, nodes, index_struct, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodes must be a list of Node objects.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service_context \u001b[38;5;241m=\u001b[39m service_context \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mServiceContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_defaults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context \u001b[38;5;241m=\u001b[39m storage_context \u001b[38;5;129;01mor\u001b[39;00m StorageContext\u001b[38;5;241m.\u001b[39mfrom_defaults()\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_docstore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mdocstore\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\llama_index\\service_context.py:178\u001b[0m, in \u001b[0;36mServiceContext.from_defaults\u001b[1;34m(cls, llm_predictor, llm, prompt_helper, embed_model, node_parser, text_splitter, transformations, llama_logger, callback_manager, system_prompt, query_wrapper_prompt, pydantic_program_mode, chunk_size, chunk_overlap, context_window, num_output, chunk_size_limit)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m llm_predictor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLMPredictor is deprecated, please use LLM instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 178\u001b[0m llm_predictor \u001b[38;5;241m=\u001b[39m llm_predictor \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mLLMPredictor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpydantic_program_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpydantic_program_mode\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(llm_predictor, LLMPredictor):\n\u001b[0;32m    182\u001b[0m     llm_predictor\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mcallback_manager \u001b[38;5;241m=\u001b[39m callback_manager\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\llama_index\\llm_predictor\\base.py:109\u001b[0m, in \u001b[0;36mLLMPredictor.__init__\u001b[1;34m(self, llm, callback_manager, system_prompt, query_wrapper_prompt, pydantic_program_mode)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    102\u001b[0m     llm: Optional[LLMType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m     pydantic_program_mode: PydanticProgramMode \u001b[38;5;241m=\u001b[39m PydanticProgramMode\u001b[38;5;241m.\u001b[39mDEFAULT,\n\u001b[0;32m    107\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize params.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback_manager:\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mcallback_manager \u001b[38;5;241m=\u001b[39m callback_manager\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\llama_index\\llms\\utils.py:31\u001b[0m, in \u001b[0;36mresolve_llm\u001b[1;34m(llm)\u001b[0m\n\u001b[0;32m     29\u001b[0m         validate_openai_api_key(llm\u001b[38;5;241m.\u001b[39mapi_key)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 31\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     32\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m******\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load OpenAI model. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you intended to use OpenAI, please check your OPENAI_API_KEY.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTo disable the LLM entirely, set llm=None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m******\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m         )\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(llm, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     42\u001b[0m     splits \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: \n******\nCould not load OpenAI model. If you intended to use OpenAI, please check your OPENAI_API_KEY.\nOriginal error:\nNo API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n\nTo disable the LLM entirely, set llm=None.\n******"
     ]
    }
   ],
   "source": [
    "from llama_index import load_index_from_storage\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "loaded_index = load_index_from_storage(StorageContext.from_defaults(persist_dir=\"./storage\"), llm=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a00db1e-cf93-4371-a12b-dd9bacc57c9a",
   "metadata": {},
   "source": [
    " \n",
    "retriever = index.as_retriever(similarity_top_k=top_k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca4e57f-c085-4474-8588-52010923b8b2",
   "metadata": {},
   "source": [
    "loaded_index = load_index_from_disk(StorageContext.from_defaults(persist_dir=\"./storage\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8779b48f-dcb7-4a73-9fcb-ce4de57bc672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Skip to main content', 'Skip to main content']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_data[0].texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754c905-4fb9-434c-8f48-8593cd664343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
