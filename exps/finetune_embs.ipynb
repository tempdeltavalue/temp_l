{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d28930a-8b8b-44e6-8097-c99375bf37c9",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6340211a-db64-458f-b3fb-4b87f09ab743",
   "metadata": {},
   "source": [
    "### Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd53aa4c-b83b-41a3-9b73-498aca71e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import InputExample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70df8f69-9d40-4467-9755-5582b4ca5178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"BAAI/bge-small-en\"\n",
    "model = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3502aaba-3e8a-42a6-9665-9d59304e798b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd0ab4-6687-4b54-aff7-b30aa96f3698",
   "metadata": {},
   "source": [
    "### Define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad17db1-e4b6-4c54-9242-905fb9cd9451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfaf8851-5d25-45c0-876a-5dbccaff0a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_example_path = os.getcwd() + '/data/What_Is_Mathematics_An_Elementary_Approach_to_Ideas_and_Methods.txt'\n",
    "\n",
    "with open(math_example_path, \"r\",  encoding=\"utf8\") as f:\n",
    "     math_example_text = f.read()\n",
    "\n",
    "math_sentences = math_example_text.split(\"\\n\")\n",
    "\n",
    "def generate_math_dataset(math_sentences):\n",
    "    examples = []\n",
    "    for sentence in math_sentences:\n",
    "        if len(sentence) !=0: # dummy check\n",
    "            example = InputExample(texts=[sentence]) # temp\n",
    "            examples.append(example)\n",
    "\n",
    "    return examples\n",
    "\n",
    "math_data = generate_math_dataset(math_sentences)[1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e26aa72e-c158-4d6c-862f-bb555e5e456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TRAIN_DATASET_FPATH = os.getcwd() + '/finetune_data/train_dataset.json'\n",
    "# VAL_DATASET_FPATH = os.getcwd() + '/finetune_data/val_dataset.json'\n",
    "\n",
    "# # We use a very small batchsize to run this toy example on a local machine. \n",
    "# # This should typically be much larger. \n",
    "# BATCH_SIZE = 10\n",
    "\n",
    "# with open(TRAIN_DATASET_FPATH, 'r+') as f:\n",
    "#     train_dataset = json.load(f)\n",
    "\n",
    "# with open(VAL_DATASET_FPATH, 'r+') as f:\n",
    "#     val_dataset = json.load(f)\n",
    "\n",
    "# dataset = val_dataset\n",
    "\n",
    "# from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "\n",
    "# corpus = dataset['corpus']\n",
    "# queries = dataset['queries']\n",
    "# relevant_docs = dataset['relevant_docs']\n",
    "# evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f07e006a-9a08-4961-b639-66a7a65bc603",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7b7f2f2-0012-4ec7-8f44-1909d42c84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = DataLoader(\n",
    "    #generate_db_dataset(train_dataset), \n",
    "    math_data,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8acef2-8618-4afa-84e0-cd959d181208",
   "metadata": {},
   "source": [
    "### Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bd4e6b0f-8ffd-4f40-bbc8-bb307c32e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.sbert.net/docs/package_reference/losses.html#multiplenegativesrankingloss\n",
    "from sentence_transformers import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "928eec1f-0f47-4bac-9189-7b791e81024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = losses.MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95044745-c271-40b3-a6d9-dd646ab281de",
   "metadata": {},
   "source": [
    "### Define evaluator "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5deb95-6d9a-4da8-ba46-f0317b12d6df",
   "metadata": {},
   "source": [
    "### Run training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "99ff9b09-c191-4ac0-a89e-629031e648d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f3b6afdf-87d6-40be-b6fd-36f89dbb3612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:07,  1.22it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:06,  1.33it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:05,  1.29it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.38it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.41it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.35it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.30it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:06<00:01,  1.33it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.35it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.36it/s]\u001b[A\n",
      "Epoch:  10%|███████▌                                                                    | 1/10 [00:07<01:06,  7.36s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:06,  1.47it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.45it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:05,  1.37it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.43it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.43it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.36it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.30it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:06<00:01,  1.32it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.34it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\u001b[A\n",
      "Epoch:  20%|███████████████▏                                                            | 2/10 [00:14<00:59,  7.41s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:05,  1.54it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.53it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:04,  1.44it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:03,  1.52it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.51it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.43it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.37it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.38it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.39it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.40it/s]\u001b[A\n",
      "Epoch:  30%|██████████████████████▊                                                     | 3/10 [00:21<00:51,  7.30s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:06,  1.50it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:05,  1.40it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.48it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.40it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.33it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.36it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.38it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.38it/s]\u001b[A\n",
      "Epoch:  40%|██████████████████████████████▍                                             | 4/10 [00:29<00:43,  7.27s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:06,  1.40it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.43it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:05,  1.36it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.44it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.44it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.39it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.35it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.38it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.39it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.40it/s]\u001b[A\n",
      "Epoch:  50%|██████████████████████████████████████                                      | 5/10 [00:36<00:36,  7.24s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:05,  1.53it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.50it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:05,  1.38it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.45it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.48it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.41it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.36it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.40it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.40it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.41it/s]\u001b[A\n",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 6/10 [00:43<00:28,  7.19s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:06,  1.48it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.48it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:04,  1.42it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.41it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.37it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.39it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.38it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.39it/s]\u001b[A\n",
      "Epoch:  70%|█████████████████████████████████████████████████████▏                      | 7/10 [00:50<00:21,  7.19s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:05,  1.58it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:04,  1.41it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.45it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.47it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.38it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.32it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.35it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.36it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.38it/s]\u001b[A\n",
      "Epoch:  80%|████████████████████████████████████████████████████████████▊               | 8/10 [00:57<00:14,  7.22s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:05,  1.58it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.53it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:04,  1.41it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.45it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.43it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.35it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.30it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:06<00:01,  1.32it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.34it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\u001b[A\n",
      "Epoch:  90%|████████████████████████████████████████████████████████████████████▍       | 9/10 [01:05<00:07,  7.28s/it]\n",
      "Iteration:   0%|                                                                                | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  10%|███████▏                                                                | 1/10 [00:00<00:06,  1.49it/s]\u001b[A\n",
      "Iteration:  20%|██████████████▍                                                         | 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
      "Iteration:  30%|█████████████████████▌                                                  | 3/10 [00:02<00:04,  1.44it/s]\u001b[A\n",
      "Iteration:  40%|████████████████████████████▊                                           | 4/10 [00:02<00:04,  1.47it/s]\u001b[A\n",
      "Iteration:  50%|████████████████████████████████████                                    | 5/10 [00:03<00:03,  1.46it/s]\u001b[A\n",
      "Iteration:  60%|███████████████████████████████████████████▏                            | 6/10 [00:04<00:02,  1.40it/s]\u001b[A\n",
      "Iteration:  70%|██████████████████████████████████████████████████▍                     | 7/10 [00:05<00:02,  1.33it/s]\u001b[A\n",
      "Iteration:  80%|█████████████████████████████████████████████████████████▌              | 8/10 [00:05<00:01,  1.35it/s]\u001b[A\n",
      "Iteration:  90%|████████████████████████████████████████████████████████████████▊       | 9/10 [00:06<00:00,  1.35it/s]\u001b[A\n",
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\u001b[A\n",
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [01:12<00:00,  7.27s/it]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Definition of of callbak should be after model init\n",
    "class MLFlowCallback:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def __call__(self, score, epoch, steps) -> None:\n",
    "        print(self.model)\n",
    "        print(score, epoch, steps)\n",
    "        mlflow.log_metric('score', score)\n",
    "        # https://mlflow.org/docs/latest/tracking/artifacts-stores.html\n",
    "\n",
    "mlflow_callback = MLFlowCallback(model)\n",
    "           \n",
    "warmup_steps = int(len(loader) * EPOCHS * 0.1)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model.fit(\n",
    "        train_objectives=[(loader, loss)],\n",
    "        epochs=EPOCHS,\n",
    "        warmup_steps=warmup_steps,\n",
    "        output_path='exp_finetune',\n",
    "        show_progress_bar=True,\n",
    "        #evaluator=evaluator, \n",
    "        evaluation_steps=50,\n",
    "        callback=mlflow_callback \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f6304d1f-aecf-42ff-9852-03f49bde8f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### llamaindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0851e2dc-6346-4a27-be11-a9874ec66493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|█████████████████████████████████████████████████████████████| 133M/133M [02:29<00:00, 895kB/s]\n",
      "tokenizer_config.json: 100%|███████████████████████████████████████████████████████████| 366/366 [00:00<00:00, 366kB/s]\n",
      "vocab.txt: 100%|█████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 983kB/s]\n",
      "tokenizer.json: 100%|███████████████████████████████████████████████████████████████| 711k/711k [00:00<00:00, 1.40MB/s]\n",
      "special_tokens_map.json: 100%|█████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 125kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name='BAAI/bge-small-en-v1.5' embed_batch_size=10 callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x000001D86B0DBD50> tokenizer_name='BAAI/bge-small-en-v1.5' max_length=512 pooling=<Pooling.CLS: 'cls'> normalize=True query_instruction=None text_instruction=None cache_folder=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index import ServiceContext, VectorStoreIndex\n",
    "from llama_index.schema import TextNode\n",
    "from llama_index.embeddings import HuggingFaceEmbedding# OpenAIEmbedding\n",
    "import os\n",
    "\n",
    "MODEL_PATH = \"BAAI/bge-small-en-v1.5\" #os.getcwd() + r'\\exp_finetune'\n",
    "embed_model = HuggingFaceEmbedding(MODEL_PATH)\n",
    "\n",
    "print(embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "221944fc-538f-4e85-809b-3e7f3ff244a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 215.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/run-llama/llama_index/issues/10051\n",
    "top_k = 5\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=None)\n",
    "\n",
    "math_nodes = [TextNode(id_=example.texts[0], text=example.texts[0]) for example in math_data] \n",
    "\n",
    "nodes = [TextNode(id_=index, text=input_example.texts[0]) for index, input_example in enumerate(math_data)] #math_data.items()] \n",
    "index = VectorStoreIndex(\n",
    "    nodes, \n",
    "    service_context=service_context, \n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "retriever = index.as_retriever(similarity_top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "750ac97d-4e36-4052-b848-4cee0c1a41be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "_m\n",
      "\n",
      "as anything can be, but the character of this statement is not the same\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: Who am I?\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "# TEST \n",
    "\n",
    "#retriever = loaded_index.as_retriever(similarity_top_k=top_k)\n",
    "new_query_engine = index.as_query_engine()\n",
    "response = new_query_engine.query(\"Who am I?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "273ee10f-d5e2-4c37-9943-041f7d70ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index.storage_context.persist(persist_dir=\"./storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8ff003d-d523-420f-8763-9b580450f06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tempdelta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\generation\\utils.py:1128: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Djjas, who is also a member of the National Council of the Muslim Brotherhood, said the\n"
     ]
    }
   ],
   "source": [
    "# Wrap seq 2 seq model into custom llm model\n",
    "\n",
    "from typing import Optional, List, Mapping, Any\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "\n",
    "from llama_index.llms import (\n",
    "    CustomLLM,\n",
    "    CompletionResponse,\n",
    "    CompletionResponseGen,\n",
    "    LLMMetadata,\n",
    ")\n",
    "from llama_index.llms.base import llm_completion_callback\n",
    "\n",
    "class OurLLM(CustomLLM):\n",
    "    context_window: int = 3900\n",
    "    num_output: int = 256\n",
    "    model_name: str = \"custom\"\n",
    "    dummy_response: str = \"My response\"\n",
    "    tokenizer: GPT2Tokenizer = None\n",
    "    model: GPT2LMHeadModel = None\n",
    "\n",
    "    def __init__(self, tokenizer, model):\n",
    "        super(CustomLLM, self).__init__()\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    @property\n",
    "    def metadata(self) -> LLMMetadata:\n",
    "        \"\"\"Get LLM metadata.\"\"\"\n",
    "        return LLMMetadata(\n",
    "            context_window=self.context_window,\n",
    "            num_output=self.num_output,\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def complete(self, prompt: str, **kwargs: Any) -> CompletionResponse:\n",
    "        input_ids = tokenizer.encode(prompt, add_special_tokens=True, return_tensors='pt')\n",
    "        output = model.generate(input_ids)\n",
    "\n",
    "        return tokenizer.decode(output[0])\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def stream_complete(\n",
    "        self, prompt: str, **kwargs: Any\n",
    "    ) -> CompletionResponseGen:\n",
    "        response = \"\"\n",
    "        for token in self.dummy_response:\n",
    "            response += token\n",
    "            yield CompletionResponse(text=response, delta=token)\n",
    "\n",
    "\n",
    "output_dir = \"./finetuned_llm\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
    "llm_model = GPT2LMHeadModel.from_pretrained(output_dir) \n",
    "input_ids = tokenizer.encode(\"Djjas\", add_special_tokens=True, return_tensors='pt')\n",
    "output = llm_model.generate(input_ids)\n",
    "\n",
    "print(tokenizer.decode(output[0]))\n",
    "\n",
    "\n",
    "# define our LLM\n",
    "llm = OurLLM(tokenizer, llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a89dc3ef-da97-4f74-9177-340dd648c028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import load_index_from_storage\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index import ServiceContext\n",
    "\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=None, #LLM\n",
    "    embed_model=embed_model,\n",
    ")\n",
    "\n",
    "loaded_index = load_index_from_storage(storage_context=StorageContext.from_defaults(persist_dir=\"./storage\"), service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "723acb7a-9650-48ae-bf23-fe112838d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = loaded_index.as_retriever(similarity_top_k=top_k)\n",
    "new_query_engine = loaded_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a00db1e-cf93-4371-a12b-dd9bacc57c9a",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8779b48f-dcb7-4a73-9fcb-ce4de57bc672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "requirements in effect on such day (including basic, supplemental, marginal and emergency reserves under any regulations of the Board orother Governmental Authority having jurisdiction with respect thereto) dealing with reserve requirements prescribed for eurocurrencyfunding (currently referred to as “Eurocurrency Liabilities” in Regulation D of the Board) maintained by a member bank of the FederalReserve System.“Application” means a Letter of Credit application or agreement in the form approved by the applicable Issuing Bank, executed anddelivered by the Borrower to the Administrative Agent and the applicable Issuing Bank requesting such Issuing Bank to issue a Letter ofCredit.“Approved Fund” means any Person (other than a natural person) that is engaged in making, purchasing, holding or investing inbank loans and similar extensions of credit in the ordinary course of its activities and that is administered or managed by (a) a Lender, (b) anAffiliate of a Lender or (c) an entity or an Affiliate of an entity that administers or manages a Lender.“Arranger” means each of Barclays, Citigroup, Goldman Sachs and MSSF, in its capacity as a joint lead arranger and a jointbookrunner.“Assignment and Assumption” means an assignment and assumption entered into by a Lender and an assignee (with the consent ofany party whose consent is required by Section 9.04), and accepted by the Administrative Agent, substantially in the form of Exhibit A or anyother form approved by the Administrative Agent.“Australian Dollars” means the lawful currency of Australia.“Australian Bank Bill Rate” means, with respect to each Interest Period for an Australian Bank Bill Rate Loan, the rate per annumequal to the following:(a) the average bid rate (the “BBR Screen Rate”) displayed at or about 10:30 a.m. (Sydney, Australia time) on the first dayof that Interest Period on the Reuters screen BBSY page for a term equivalent to such Interest Period; or(b) to the extent:(i)    the BBR Screen Rate is not displayed for a term equivalent to such Interest Period; or(ii)    the basis on which the BBR Screen Rate is calculated or displayed is changed and the relevant Lenders’ instructthe Administrative Agent (after consultation by the Administrative Agent with the Borrower) that in their opinion it ceases toreflect the relevant Lenders’ cost of funding a new Australian Bank Bill Rate Loan to the same extent as at the date of thisAgreement,the Administrative Agent on instructions of the relevant Lenders may specify another page or service displaying the appropriate rateafter consultation by the Administrative Agent with the Borrower; or(c) if there are no buying rates, the Australian Bank Bill Rate for each Lender will be the rate notified by that Lender to theAdministrative Agent to be that Lender’s cost of funding its participation in the relevant Australian Bank Bill Rate Loans for thatperiod. Rates will be4\n",
      "\n",
      "EXHIBIT INDEXExhibitNo.Exhibit DescriptionProvided Incorporated by ReferenceHerewithFormFile NumberExhibitFiling Date3.1Amended and Restated Certificate of Incorporation ofthe Registrant.10-Q001-389023.1August 5, 20213.2Amended and Restated Bylaws of the Registrant.10-Q001-389023.2August 5, 20214.1Description of Common Stock.10-K001-389024.1March 2, 20204.2Form of common stock certificate of the Registrant.S-1/A333-2308124.1April 26, 20194.5Indenture, relating to the Registrant’s 8.00% SeniorNotes due 2026, by and between the Registrant and U.S.Bank National Association, dated November 7, 2018.S-1333-2308124.5April 11, 20194.6Form of 8.00% Senior Note due 2026.S-1333-2308124.6April 11, 20194.7Indenture, dated as of September 17, 2019, by andbetween the Registrant, Rasier, LLC and U.S. BankNational Association as Trustee.8-K001-389024.1September 17, 20194.8Form of Global Note, representing the Registrant’s7.500% Senior Notes due 2027 (included as Exhibit A tothe Indenture filed as Exhibit 4.1).8-K001-389024.2September 17, 20194.9Form of Unsecured Convertible Note.10-Q001-389024.1May 8, 20204.10Indenture, dated as of May 15, 2020, by and between theRegistrant, Rasier, LLC and U.S. Bank NationalAssociation, as Trustee.8-K001-389024.1May 15, 20204.11Form of Global Note, representing the Registrant’s7.500% Senior Notes due 2025 (included as Exhibit A tothe Indenture filed as Exhibit 4.1).8-K001-389024.2May 15, 20204.12Indenture, dated as of September 16, 2020, by andbetween the Registrant, Rasier, LLC and U.S. BankNational Association, as Trustee.8-K001-389024.1September 16, 20204.13Form of Global Note, representing the Registrant’s6.250% Senior Notes due 2028 (included as Exhibit A tothe Indenture filed as Exhibit 4.1).8-K001-389024.2September 16, 20204.14Indenture, dated as of December 11, 2020, by andbetween the Registrant and U.S. Bank NationalAssociation, as Trustee.8-K001-389024.1December 11, 20204.15Form of Global Note, representing the Registrant’s 0%Convertible Senior Notes due 2025 (included as ExhibitA to the Indenture filed as Exhibit 4.1).8-K001-389024.2December 11, 20204.16Indenture, dated as of August 12, 2021, by and betweenthe Registrant, Rasier, LLC and U.S. Bank NationalAssociation, as Trustee.8-K001-389024.1August 12, 20214.17Form of Global Note, representing the Registrant’s4.50% Senior Notes due 2029 (included as Exhibit A tothe Indenture filed as Exhibit 4.1).8-K001-389024.2August 12, 202110.1Amended and Restated 2010 Stock Plan and relatedforms of award agreements.S-1333-23081210.1April 11, 201910.2Amended and Restated 2013 Equity Incentive Plan andrelated forms of award agreements.S-1/A333-23081210.2April 26, 201910.32019 Equity Incentive Plan and related forms of awardagreements.S-1333-23081210.3April 11, 201910.42019 Employee Stock Purchase Plan.S-1333-23081210.4April 11, 201910.5Form of Indemnification Agreement between theRegistrant and each of its directors and executiveofficers.S-1333-23081210.5April 11, 201910.62019 Executive Severance Plan.S-1333-23081210.6April 11, 201910.7Executive Bonus Plan.S-1333-23081210.7April 11, 2019149\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: What is math?\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "response = new_query_engine.query(\"What is math?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212e1702-28fb-45fb-b095-5ef00f948336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
